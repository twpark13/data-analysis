# League of Legends 15 min. Data Analysis

## Topic

### Goals

- 15분 시점의 게임 데이터가 게임 승패 여부와 어떤 연관을 갖는가에 대해 연구
- 해당 데이터를 이용한 게임 승패 예측 모델 생성

### Why League of Legends?

다음 3 가지 조건에 부합하기 때문에 주제로 선정하였다.

1. 게임 데이터를 비교적 쉽게 입수할 수 있다.
	- 데이터가 공개되어 있는 게임들은 생각보다 많지 않으며, 개인이 직접 게임 데이터를 수집하는데는 한계가 있다.

2. 해당 게임을 플레이 해 본 적이 있으며, 기본적인 이해도를 가지고 있다.
	- 물론 내가 모르는 분야여도 데이터 분석을 진행할 수 있지만, 해당 분야의 도메인 지식을 가지고 있다면 더 높은 수준의 분석이 가능하다.

3. 많은 사람들이 알고 있는 게임이다.
	- 독자들도 본인들이 알고 있는 분야일 시 더 흥미를 보일 것이라 생각하였다.

### Why 15 min.?

사실 처음에는 게임이 끝난 시점의 데이터를 활용한 분석을 진행할 계획이었다. 
하지만 분석 진행 도중 문제점을 발견했는데, 경기 결과만 놓고 분석을 하다보면 다소 진부한 결론으로 이어질 수 밖에 없다.
승리한 팀에서 평균적으로 킬을 더 많이 기록하고, 건물을 더 많이 파괴하고 (애초에 넥서스를 파괴해야 이기는 게임이다), 골드를 더 많이 벌었다 등은 지극히 당연한 얘기로 굳이 데이터 분석을 할 필요도 없다.
경기가 끝난 시점의 데이터를 분석하는 것 보다는 게임 초반의 데이터가 경기 결과와 어떤 연관이 있을까? 가 훨씬 더 흥미로운 주제라고 생각하였다.

구체적으로 15분을 타깃으로 설정한 이유는, 15분이 게임 페이즈가 바뀌는 시기라고 생각했기 때문이다. 
챔피언 킬이 발생한 좌표들을 통해 맵의 어떤 지점에서 교전이 일어나는지를 알 수 있는데, 게임 초반 단계에는 라이너들이 본인의 라인 근처에서 주로 활동하지만, 15분이 가까워 질 수록 미드 라인에서 교전이 발생하는 빈도가 급격히 높아진다. 
(자세한 내용은 Exploratory Data Analysis 참조)
또 다른 근거로, LCK 공식 블로그 에서 제공하는 각종 지표에도 15분 시점의 지표들이 상당수 포함되어 있다. 리그 오브 레전드 경기를 연구하는 사람들도 15분 시점을 특별하게 여기기 때문에 그런 것 이라고 생각한다.


## Data preprocessing

### Data info

게임 버전: 12.8 (22.4.27~22.5.10)

- 패치마다 메타가 바뀌기 때문에 모든 데이터들의 게임 버전을 통일하는 것이 중요하다고 판단하였다. 게임 데이터 수집을 시작한 시점이 5월 중순이었기 때문에 12.8 버전을 사용하였다.

대상: 다이아 1티어 유저가 플레이 한 경기 시간이 16분 이상인 랭크 게임

- 플레이 데이터를 통해 일반화된 이론을 정립하기 위해서는 플레이어들의 게임 이해도가 높아야 하고, 집단 내 플레이어 들의 실력들이 비슷해야 한다고 생각했다. 

챌린저, 그랜드마스터, 마스터 티어는 유저 수가 많지 않기 때문에 표본 수집에 어려움이 있을 것 같아 다이아 1티어 유저들을 대상으로 설정하였다.


### Download data via Riot API

데이터 크기: 총 70,000 게임, 90:10 비율로 train test split 진행

기존 계획은 10만 게임 이상의 데이터를 확보하는 것 이었으나, 여러가지 현실적인 문제로 인해 목표치를 하향조정 하였다.

- API call 도중 서버와의 연결이 끊어지는 문제가 빈번히 발생함
- API key의 유효 기간은 짧으며 갱신을 반드시 key 만료 이후 수동으로 해야 함
- 개인사정으로 인해 컴퓨터를 하루 종일 가동할 수 없음
- 데이터 파일의 용량이 큼 (약 7만 게임의 데이터 파일은 100GB 이상의 용량을 요구)

7만개의 게임 데이터 파일을 받기 위해서는 15만 회 이상의 API call을 필요로 하는데, Riot API는 2분당 100회의 API call을 허용한다.
산술적으로는 50시간 정도가 필요되지만, 실제로는 상술한 이유들로 인해 데이터 파일을 받는 데에만 열흘 이상 소요되었다.
분석 및 모델링 단계에서도 데이터가 클 시 소요되는 시간이 커지기 때문에 적정선에서 타협을 하게 되었다.

용량 문제로 인해 raw data를 전부 업로드 하기 어려운 관계로 timeline 및 match 파일은 5개씩만 샘플로 업로드하였다. 
게임 데이터에서 챔피언 킬 정보만 따로 추출한 파일 또한 단일 용량이 100MB를 초과하는 관계로 업로드하지 못 하였으며, 이외의 사용된 파일은 모두 업로드 하였다.

상세 과정은 [preprocessing](/league-of-legends/preprocessing.ipynb)  참조


## Exploratory Data Analysis

[analysis](/league-of-legends/analysis.ipynb) 참조

## Modeling

deep learning 보다는 machine learning이 설명에 더 용이하다고 판단하여 이를 이용하기로 결정하였다. 
분류 알고리즘으로 Random Forest, Logistic Regression, XGBoost, LightGBM, Extra Trees, AdaBoost, BaggingClassifier, Gaussian Naive Bayes, SVM, K Nearest Neighbor, Gradient Boosting 등을 시도하였고,
feature selection에 Permutation Importance, RFECV 등을 사용하였고,
hyperparameter tuning 에는 RandomizedSearchCV, GridSearchCV를 사용, 
ensemble 기법으로 Stacking, Voting (hard, soft) 등을 시도하였다.

최종 모델: Logistic Regression
Test Accuracy: 0.8019

feature selection 및 hyperparameter tuning 과정은 분량이 많아 일부 생략된 부분이 있다.

자세한 사항은 [modeling](/league-of-legends/modeling.ipynb) 참조


## Conclusion

어떤 지표가 게임 결과와 연관이 높은지에 대해 대략적으로 파악할 수 있었다. 

지나치게 영향력이 큰 변수(양 팀의 골드 차)가 존재하여 분석 및 모델링 방향에 난점이 있었다.

생성한 예측 모델이 test set에서 80% 이상의 정확도를 기록하였다.
