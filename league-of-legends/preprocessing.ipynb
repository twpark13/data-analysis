{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from time import time, sleep\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-screening",
   "metadata": {},
   "source": [
    "API key는 https://developer.riotgames.com/apis 에서 발급 받을 수 있다. 발급 시점으로 부터 24시간 동안 유효하고, 만료 시 재발급 받아야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'RGAPI-********-****-****-****-************' # API 키를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.41 Safari/537.36 Edg/101.0.1210.32\",\n",
    "    \"Accept-Language\": \"ko,en;q=0.9,en-US;q=0.8\",\n",
    "    \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "    \"Origin\": \"https://developer.riotgames.com\",\n",
    "    \"X-Riot-Token\": api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-optics",
   "metadata": {},
   "source": [
    "Riot API key는 1초당 최대 20회, 2분당 최대 100회까지 호출 가능하며 횟수를 초과할 시 에러가 발생한다.\n",
    "\n",
    "에러를 방지하기 위해, api call이 발생할 때 마다 발생된 시각과 100회 이전의 api call이 발생한 시각을 비교하여 이들의 차이가 120초보다 작을 시, 120초보다 작은 만큼 대기 하는 방법을 사용하였다. (실제로는 오차가 발생할 수 있음을 감안하여 121초를 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "living-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSequence:\n",
    "\n",
    "    def __init__(self, seq=deque([0]*100)):\n",
    "        self.seq = seq\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        diff = time() - self.seq.popleft()\n",
    "        \n",
    "        if diff < 121:\n",
    "            sleep(121-diff)\n",
    "            \n",
    "        self.seq.append(time())\n",
    "        \n",
    "        \n",
    "Time = TimeSequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-transportation",
   "metadata": {},
   "source": [
    "다음의 과정을 통해 원하는 정보들을 조회하였다.\n",
    "\n",
    "\n",
    "1. 찾고자 하는 tier-division에 속해 있는 league를 조회\n",
    "2. 1.에서 찾은 league들에 소속되어 있는 유저들의 summonerID를 조회\n",
    "3. 2.에서 찾은 summonerID들의 puuid를 조회\n",
    "4. 3.에서 찾은 puuid들의 matchID를 조회\n",
    "5. 4.에서 찾은 matchID들의 timeline data를 조회\n",
    "6. 4.에서 찾은 matchID들의 match data를 조회\n",
    "\n",
    "분석 대상이 timeline data임에도 match data 파일을 다운 받은 이유는 해당 파일에 필요한 추가정보가 있어서 이다. (자세한 사항은 후술)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electronic-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leagueId(tier, division):\n",
    "    url = f'https://kr.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/{tier}/{division}?page=1'\n",
    "    Time.update()\n",
    "    league_entries = requests.get(url, headers=request_header).json()\n",
    "    return list(set(pd.DataFrame(league_entries)['leagueId']))\n",
    "\n",
    "def get_summonerId(leagueId):  \n",
    "    url = f'https://kr.api.riotgames.com/lol/league/v4/leagues/{leagueId}'\n",
    "    Time.update()\n",
    "    league = requests.get(url, headers=request_header).json()\n",
    "    return list(pd.DataFrame(league['entries'])['summonerId'])\n",
    "\n",
    "def get_puuid(summonerId):\n",
    "    url = f'https://kr.api.riotgames.com/lol/summoner/v4/summoners/{summonerId}'\n",
    "    Time.update()\n",
    "    return requests.get(url, headers=request_header).json()['puuid']\n",
    "\n",
    "def get_matchId(puuid, startTime=1651158000):\n",
    "    url = f'https://asia.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?startTime={startTime}&type=ranked&start=0&count=100'\n",
    "    Time.update()\n",
    "    return requests.get(url, headers=request_header).json()\n",
    "\n",
    "def get_timeline(matchId):\n",
    "    url = f'https://asia.api.riotgames.com/lol/match/v5/matches/{matchId}/timeline'\n",
    "    Time.update()\n",
    "    return requests.get(url, headers=request_header).json()\n",
    "\n",
    "def get_match(matchId):\n",
    "    url = f'https://asia.api.riotgames.com/lol/match/v5/matches/{matchId}'\n",
    "    Time.update()\n",
    "    return requests.get(url, headers=request_header).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liberal-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching league entries...\n",
      "Total 172 league entries found. (0.74 sec)\n"
     ]
    }
   ],
   "source": [
    "print(f'Searching league entries...')\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "leagueId = get_leagueId('DIAMOND', 'I')\n",
    "\n",
    "print(f'Total {len(leagueId)} league entries found. ({time()-start_time:.2f} sec)')\n",
    "\n",
    "with open('data/leagueId', 'wb') as fp:\n",
    "    pickle.dump(leagueId, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "external-label",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching summoner IDs...\n"
     ]
    }
   ],
   "source": [
    "print(f'Searching summoner IDs...')\n",
    "\n",
    "start_time = time()\n",
    "summonerId = []\n",
    "\n",
    "for Id in leagueId:\n",
    "    summonerId += get_summonerId(Id)\n",
    "\n",
    "summonerId = list(set(summonerId))\n",
    "\n",
    "print(f'Total {len(summonerId)} summoner IDs found. ({(time()-start_time)/60:.2f} min)')\n",
    "\n",
    "with open('data/summonerId', 'wb') as fp:\n",
    "    pickle.dump(summonerId, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-survival",
   "metadata": {},
   "source": [
    "leagueId와 summonerId를 찾는 데에는 많은 시간이 소요되지 않으나, 이후 작업 부터는 필요한 api call 횟수가 크게 증가함에 따라 소요 시간이 길어졌다. Riot api를 사용하는 도중 각종 에러가 발생하였는데, 에러 발생 시 일정 시간 이후 다시 연결을 시도할 수 있게 하였고, 이를 통해서도 해결되지 않는 경우에 대비하여 다운받은 정보를 주기적으로 백업하는 과정을 추가하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "round-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "registered-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 40 puuids found. (0.19 min)\n"
     ]
    }
   ],
   "source": [
    "if load:\n",
    "    with open('data/summonerId_temp', 'rb') as fp:\n",
    "        summonerId = pickle.load(fp)\n",
    "        \n",
    "    with open('data/puuid_temp', 'rb') as fp:\n",
    "        puuid = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    puuid = []\n",
    "\n",
    "    \n",
    "summonerId, puuid = deque(summonerId), deque(puuid)\n",
    "\n",
    "c, end = 0, len(summonerId)\n",
    "start_time = time()\n",
    "num_api_call = 0\n",
    "\n",
    "\n",
    "while c < end:\n",
    "    try: \n",
    "        puuid.append(get_puuid(summonerId.popleft()))\n",
    "        num_api_call += 1\n",
    "        c += 1\n",
    "        print(f'Total {c} puuids found.\\r', end='')\n",
    "\n",
    "        if num_api_call == 100:\n",
    "            with open('data/summonerId_temp', 'wb') as fp:\n",
    "                pickle.dump(summonerId, fp)\n",
    "                \n",
    "            with open('data/puuid_temp', 'wb') as fp:\n",
    "                pickle.dump(puuid, fp)\n",
    "                \n",
    "            num_api_call = 0\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        with open('data/summonerId_temp', 'wb') as fp:\n",
    "                pickle.dump(summonerId, fp)\n",
    "                \n",
    "        with open('data/puuid_temp', 'wb') as fp:\n",
    "                pickle.dump(puuid, fp)\n",
    "        \n",
    "        break\n",
    "\n",
    "    except:\n",
    "        print('Waiting for reconnection...\\r', end='')\n",
    "        sleep(120)\n",
    "        num_api_call = 0\n",
    "\n",
    "print(f'Total {len(puuid)} puuids found. ({(time()-start_time)/60:.2f} min)')\n",
    "\n",
    "with open('data/puuid', 'wb') as fp:\n",
    "    pickle.dump(puuid, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inside-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vertical-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 3478 match IDs found. (0.19 min)\n"
     ]
    }
   ],
   "source": [
    "if load:\n",
    "    with open('data/matchId_temp', 'rb') as fp:\n",
    "        matchId = pickle.load(fp)\n",
    "\n",
    "    with open('data/puuid_temp', 'rb') as fp:\n",
    "        puuid = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    puuid, matchId = deque(puuid), deque()\n",
    "    \n",
    "    \n",
    "c, end = 0, len(puuid)\n",
    "start_time = time()\n",
    "num_api_call = 0\n",
    "\n",
    "\n",
    "while c < end:\n",
    "    try: \n",
    "        matchId.extend(get_matchId(puuid.popleft()))\n",
    "        num_api_call += 1\n",
    "        c += 1\n",
    "        print(f'{c}/{end} puuids completed.\\r', end='')\n",
    "\n",
    "        if num_api_call == 100:\n",
    "            with open('data/matchId_temp', 'wb') as fp:\n",
    "                pickle.dump(matchId, fp)\n",
    "                \n",
    "            with open('data/puuid_temp', 'wb') as fp:\n",
    "                pickle.dump(puuid, fp)\n",
    "                \n",
    "            num_api_call = 0\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        with open('data/matchId_temp', 'wb') as fp:\n",
    "            pickle.dump(matchId, fp)\n",
    "\n",
    "        with open('data/puuid_temp', 'wb') as fp:\n",
    "            pickle.dump(puuid, fp)\n",
    "        \n",
    "        break\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        print('Waiting for reconnection...\\r', end='')\n",
    "        sleep(120)\n",
    "\n",
    "\n",
    "matchId = list(set(matchId))\n",
    "print(f'Total {len(matchId)} match IDs found. ({(time()-start_time)/60:.2f} min)')\n",
    "\n",
    "with open('data/matchId', 'wb') as fp:\n",
    "    pickle.dump(matchId, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fixed-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-boulder",
   "metadata": {},
   "source": [
    "분석 대상이 게임 시작 후 15분 시점이므로 길이가 최소 16분인 게임들만 다운받기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/51914 match IDs completed.\r"
     ]
    }
   ],
   "source": [
    "if load:\n",
    "    with open('data/matchId', 'rb') as fp:\n",
    "        matchId = pickle.load(fp)\n",
    "        \n",
    "    with open('data/invalid', 'rb') as fp:\n",
    "        invalid = pickle.load(fp)\n",
    "    \n",
    "    match = [i[:-5] for i in os.listdir('data/match')]\n",
    "    matchId = deque(set(matchId) - set(match) - set(invalid))\n",
    "    \n",
    "else:\n",
    "    invalid = []\n",
    "    \n",
    "    \n",
    "c, end = 0, len(matchId)\n",
    "start_time = time()\n",
    "\n",
    "\n",
    "while c < end:\n",
    "    try:\n",
    "        fname = matchId.popleft()\n",
    "        match = get_match(fname)\n",
    "        pos = []\n",
    "        na = 0\n",
    "\n",
    "        if match['info']['gameDuration'] >= 960:\n",
    "\n",
    "            win = match['info']['teams'][0]['win']\n",
    "\n",
    "            for i in range(10):\n",
    "                participants = match['info']['participants'][i]\n",
    "\n",
    "                if participants['teamPosition'] == '':\n",
    "                    na = 1\n",
    "\n",
    "            if na:\n",
    "                invalid.append(fname)\n",
    "\n",
    "            else:\n",
    "                with open(f'data/match/{fname}.json', 'w') as fp:\n",
    "                    json.dump(match, fp, indent=4)\n",
    "\n",
    "        else:\n",
    "            invalid.append(fname)\n",
    "\n",
    "        c += 1\n",
    "\n",
    "        print(f'{c}/{end} match IDs completed.\\r', end='')\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopped.')\n",
    "        break\n",
    "    \n",
    "    except:\n",
    "        print('Waiting for reconnection...\\r', end='')\n",
    "        sleep(120)\n",
    "        \n",
    "\n",
    "print(f'{c} match data downloaded. ({(time()-start_time)/60:.2f} min)')\n",
    "\n",
    "with open('data/invalid', 'wb') as fp:\n",
    "    pickle.dump(invalid, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for reconnection....\r"
     ]
    }
   ],
   "source": [
    "files = deque(set(os.listdir('data/match')) - set(os.listdir('data/timeline')))\n",
    "    \n",
    "c, end = 0, len(files)\n",
    "start_time = time()\n",
    "    \n",
    "\n",
    "while c < end:\n",
    "    try:\n",
    "        fname = files.popleft()[:-5]\n",
    "        timeline = get_timeline(fname)\n",
    "        \n",
    "        with open(f'data/timeline/{fname}.json', 'w') as fp:\n",
    "            json.dump(timeline, fp, indent=4)\n",
    "\n",
    "        c += 1\n",
    "\n",
    "        print(f'{c}/{end} match IDs completed.\\r', end='')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopped.')\n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        print('Waiting for reconnection...\\r', end='')\n",
    "        sleep(120)\n",
    "\n",
    "print(f'{c}/{end} timeline data downloaded. ({(time()-start_time)/60:.2f} min)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-principal",
   "metadata": {},
   "source": [
    "match 파일에서 이용할 정보 중에 `teamPosition` 이라는 항목이 있다. `teamPosition`은 해당 플레이어의 게임 내 포지션을 의미하는데, timeline 파일에서는 제공되지 않는 기능이다. 사실 timeline 파일에서 위치 정보, 스펠 및 아이템를 이용하여 각 플레이어의 포지션을 유추하는 것도 충분히 가능하나 (match 파일에서 제공되는 항목도 추론된 항목이다), match 파일의 정보를 이용하는 것이 더 효율적이라고 판단하였다.\n",
    "\n",
    "일부 `teamPosition` 항목이 기재되지 않은 플레이어들이 존재하는 게임들이 있다. 해당 게임들을 찾아본 결과, 대부분 정상적으로 진행된 게임과 거리가 멀어보이는 것 같아 대상에서 제외하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "administrative-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = deque(set(os.listdir('data/match')) & set(os.listdir('data/timeline')))\n",
    "\n",
    "gameInfo, gameResult = [], []\n",
    "c, end = 0, len(files)\n",
    "start_time = time()\n",
    "\n",
    "for fname in files:\n",
    "    try:\n",
    "        match = json.load(open('data/match/' + fname))['info']\n",
    "        pos = []\n",
    "        na = 0\n",
    "\n",
    "        win = match['teams'][0]['win']\n",
    "\n",
    "        for i in range(10):\n",
    "            participants = match['participants'][i]\n",
    "            \n",
    "            if participants['teamPosition'] == '':\n",
    "                na = 1\n",
    "                    \n",
    "            pos.append((participants['teamPosition'], participants['championName']))\n",
    "            \n",
    "        if not na:\n",
    "            gameInfo.append((fname, pos))\n",
    "            gameResult.append(win)\n",
    "        \n",
    "        \n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    c += 1\n",
    "\n",
    "    print(f'{c}/{end} match IDs completed. ({(time()-start_time)/60:.2f} min)\\r', end='')\n",
    "\n",
    "        \n",
    "with open('data/gameInfo', 'wb') as fp:\n",
    "    pickle.dump(gameInfo, fp)\n",
    "\n",
    "with open('data/gameResult', 'wb') as fp:\n",
    "    pickle.dump(gameResult, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ahead-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70921"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gameInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-wilson",
   "metadata": {},
   "source": [
    "추가적인 feature engineering은 분석 및 모델링 단계에서 시행하기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "for team in ['blue','red']:\n",
    "    for loc in ['Outer', 'Inner', 'Base']:\n",
    "        for lane in ['Top', 'Mid', 'Bot']:\n",
    "            data_dict[f'{team}{loc}{lane}TurretLost'] = 0\n",
    "    \n",
    "    for loc in ['Inhibitor', 'NexusTurret']:\n",
    "        data_dict[f'{team}{loc}Lost'] = 0\n",
    "    \n",
    "    for pos in ['Top', 'Jungle', 'Middle', 'Bottom', 'Utility']:\n",
    "        for col in [\n",
    "            'ChampionName', 'Kill', 'Death', 'Assist', 'SoloKill', 'SoloKillVictim', 'WardPlaced', \n",
    "            'WardKill', 'TotalDamageDoneToChampions', 'TotalDamageTaken', 'JungleMinionsKilled',  \n",
    "            'Level', 'MinionsKilled', 'TotalGold'\n",
    "        ]:\n",
    "            data_dict[f'{team}{pos}{col}'] = 0\n",
    "    \n",
    "    for dragon in ['Air', 'Earth', 'Fire', 'Hextech', 'Water']:\n",
    "        data_dict[f'{team}{dragon}DragonKill'] = 0\n",
    "    \n",
    "    data_dict[f'{team}AceKill'] = 0\n",
    "    data_dict[f'{team}TotalDragonKill'] = 0\n",
    "    data_dict[f'{team}HeraldKill'] = 0\n",
    "\n",
    "data_dict[f'blueFirstBloodKill'] = 0\n",
    "data_dict[f'FirstBloodKiller'] = 0\n",
    "data_dict[f'FirstBloodVictim'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jewish-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BUILDING_KILL(event:dict):\n",
    "    tname = 'blue' if event['teamId'] == 100 else 'red'\n",
    "\n",
    "    if event['buildingType'] == 'TOWER_BUILDING':\n",
    "        ttype = event['towerType'][:-7].title()\n",
    "        ltype = event['laneType'][:3].title() if ttype != 'Nexus' else ''\n",
    "            \n",
    "        data[f'{tname}{ttype}{ltype}TurretLost'] += 1\n",
    "        \n",
    "    else:        \n",
    "        data[f'{tname}InhibitorLost'] += 1\n",
    "\n",
    "        \n",
    "def CHAMPION_KILL(event:dict):\n",
    "    killer = event['killerId']\n",
    "    kpos, kteam = position[killer-1][0].title(), teams[killer//6]\n",
    "    data[f'{kteam}{kpos}Kill'] += 1\n",
    "    \n",
    "    victim = event['victimId']\n",
    "    vpos, vteam = position[victim-1][0].title(), teams[victim//6]\n",
    "    data[f'{vteam}{vpos}Death'] += 1\n",
    "    \n",
    "    try:\n",
    "        assist = event['assistingParticipantIds']\n",
    "        \n",
    "        for p in assist:\n",
    "            ppos, pteam = position[p-1][0].title(), teams[p//6]\n",
    "            data[f'{pteam}{ppos}Assist'] += 1\n",
    "        \n",
    "    except KeyError:\n",
    "        data[f'{kteam}{kpos}SoloKill'] += 1\n",
    "        data[f'{vteam}{vpos}SoloKillVictim'] += 1\n",
    "        \n",
    "\n",
    "def CHAMPION_SPECIAL_KILL(event:dict):\n",
    "    if event['killType'] == 'KILL_ACE':\n",
    "        tname = teams[event['killerId']//6]\n",
    "        data[f'{tname}AceKill'] += 1\n",
    "        \n",
    "\n",
    "def ELITE_MONSTER_KILL(event:dict):\n",
    "    tname = 'blue' if event['killerTeamId'] == 100 else 'red'\n",
    "    mtype = event['monsterType'][-6:].title()\n",
    "    \n",
    "    if mtype == 'Dragon':\n",
    "        stype = event['monsterSubType'][:-7].title()\n",
    "        \n",
    "        data[f'{tname}TotalDragonKill'] += 1\n",
    "        data[f'{tname}{stype}DragonKill'] += 1\n",
    "    \n",
    "    else:\n",
    "        data[f'{tname}HeraldKill'] += 1\n",
    "        \n",
    "        \n",
    "def FIRST_BLOOD(event:dict):\n",
    "    killer = event['killerId']\n",
    "    kpos, kteam = position[killer-1][0].title(), teams[killer//6]\n",
    "    \n",
    "    if kteam == 'blue':\n",
    "        data[f'blueFirstBloodKill'] += 1\n",
    "    \n",
    "    data[f'FirstBloodKiller'] = kpos\n",
    "    \n",
    "    victim = event['victimId']\n",
    "    vpos = position[victim-1][0].title()\n",
    "    data[f'FirstBloodVictim'] = vpos\n",
    "    \n",
    "\n",
    "def WARD_PLACED(event:dict):\n",
    "    wtype = event['wardType']\n",
    "\n",
    "    if wtype not in ['UNDEFINED', 'TEEMO_MUSHROOM']:\n",
    "        cid = event['creatorId']\n",
    "        cpos, cteam = position[cid-1][0].title(), teams[cid//6]\n",
    "\n",
    "        data[f'{cteam}{cpos}WardPlaced'] += 1\n",
    "        \n",
    "\n",
    "def WARD_KILL(event:dict):\n",
    "    wtype = event['wardType']\n",
    "\n",
    "    if wtype not in ['UNDEFINED', 'TEEMO_MUSHROOM']:\n",
    "        kid = event['killerId']\n",
    "        kpos, kteam = position[kid-1][0].title(), teams[kid//6]\n",
    "\n",
    "        data[f'{kteam}{kpos}WardKill'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strong-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chicken-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70921/70921 files completed. Time spent: 40.79 min\r"
     ]
    }
   ],
   "source": [
    "if load:\n",
    "    with open('data/gameInfo', 'rb') as fp:\n",
    "        gameInfo = pickle.load(fp)\n",
    "        \n",
    "    with open('data/gameResult', 'rb') as fp:\n",
    "        gameResult = pickle.load(fp)\n",
    "\n",
    "\n",
    "teams = ['blue', 'red']\n",
    "\n",
    "stats = []\n",
    "c, end = 0, len(gameInfo)\n",
    "start_time = time()\n",
    "\n",
    "for info in gameInfo:\n",
    "    fname, position = info\n",
    "    file = json.load(open('data/timeline/' + fname))\n",
    "\n",
    "    data = data_dict.copy()\n",
    "\n",
    "    for idx, p in enumerate(position):\n",
    "        pname, cname = p\n",
    "        data[f'{teams[idx//5]}{pname.title()}ChampionName'] = cname\n",
    "\n",
    "\n",
    "    frames = file['info']['frames'][:16]\n",
    "\n",
    "    eventTypes = ['BUILDING_KILL', 'CHAMPION_KILL', 'CHAMPION_SPECIAL_KILL', 'ELITE_MONSTER_KILL', \n",
    "                   'WARD_PLACED', 'WARD_KILL']\n",
    "\n",
    "    firstblood = 0\n",
    "\n",
    "    for frame in frames:\n",
    "\n",
    "        for event in frame['events']:\n",
    "            eventType = event['type']\n",
    "\n",
    "            if firstblood == 0 and eventType == 'CHAMPION_KILL':\n",
    "                firstblood = 1\n",
    "                FIRST_BLOOD(event)\n",
    "\n",
    "            try:\n",
    "                eval(eventType + '(event)')\n",
    "\n",
    "            except NameError:\n",
    "                pass\n",
    "\n",
    "\n",
    "    cols = ['totalDamageDoneToChampions', 'totalDamageTaken', 'jungleMinionsKilled', 'level', 'minionsKilled', 'totalGold']\n",
    "\n",
    "    pf = frame['participantFrames']\n",
    "\n",
    "    for participant in pf.keys():\n",
    "        p = int(participant)\n",
    "        pos, team = position[p-1][0].title(), teams[p//6]\n",
    "\n",
    "        for col in cols[:2]:\n",
    "            cname = col[0].upper()+col[1:]\n",
    "            data[f'{team}{pos}{cname}'] = pf[participant]['damageStats'][col]\n",
    "\n",
    "        for col in cols[2:]:\n",
    "            cname = col[0].upper()+col[1:]\n",
    "            data[f'{team}{pos}{cname}'] = pf[participant][col]\n",
    "\n",
    "    stats.append(data)\n",
    "    c += 1\n",
    "    print(f'{c}/{end} files completed. Time spent: {(time() - start_time)/60:.2f} min\\r', end='')\n",
    "\n",
    "    \n",
    "stats = pd.concat([pd.DataFrame(stats), pd.DataFrame(gameResult, columns=['blueWin'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-alexandria",
   "metadata": {},
   "source": [
    "70000개의 데이터를 train 90%, test 10% 비율로 분할하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inner-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "honest-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(stats[:70000], test_size=0.1, random_state=0)\n",
    "\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-liberia",
   "metadata": {},
   "source": [
    "timeline data에서 킬과 관련된 정보들만 따로 추출하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/gameInfo', 'rb') as fp:\n",
    "    gameInfo = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "isolated-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limited-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 files completed. Time spent: 33.77 min\r"
     ]
    }
   ],
   "source": [
    "def id2pos(idx):\n",
    "    teams = ['blue', 'red']\n",
    "    return teams[idx//6] + position[idx-1][0].title()\n",
    "\n",
    "if load:\n",
    "    with open('data/gameInfo', 'rb') as fp:\n",
    "        gameInfo = pickle.load(fp)\n",
    "        \n",
    "    gameInfo, test = train_test_split(gameInfo[:70700], test_size=700, random_state=0)\n",
    "\n",
    "    \n",
    "kill = []\n",
    "end = len(gameInfo)\n",
    "start_time = time()\n",
    "cols = ['gameIdx','assistingParticipantIds', 'killerId', 'loc_x', 'loc_y', 'timestamp', 'victimId']\n",
    "\n",
    "for idx, info in enumerate(gameInfo):\n",
    "    fname, position = info\n",
    "    frames = json.load(open('data/timeline/' + fname))['info']['frames'][:16]\n",
    "    \n",
    "    for frame in frames:\n",
    "        for event in frame['events']:\n",
    "            event_type = event['type']\n",
    "            \n",
    "            if event_type == 'CHAMPION_KILL':\n",
    "                event['killerId'], event['victimId'] = id2pos(event['killerId']), id2pos(event['victimId'])\n",
    "                event['gameIdx'] = idx\n",
    "                \n",
    "                try:\n",
    "                    event['assistingParticipantIds'] = [id2pos(pid) for pid in event['assistingParticipantIds']]\n",
    "                    \n",
    "                except KeyError:\n",
    "                    event['assistingParticipantIds'] = np.NaN\n",
    "                \n",
    "                event['loc_x'], event['loc_y'] = event['position'].values()\n",
    "                kill.append([event[col] for col in cols])\n",
    "                \n",
    "    print(f'{idx+1}/{end} files completed. Time spent: {(time() - start_time)/60:.2f} min\\r', end='')\n",
    "\n",
    "kill = pd.DataFrame(kill, columns=cols)\n",
    "kill.to_csv('killLocation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
